{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2. Local Inference\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "이 튜토리얼에서는 이전 노트북에서 Amazon SageMaker의 Tensorflow 1.x 사용자 스크립트로 학습한 MobileNet 모델 아티팩트 중 네트워크 구조와 가중치를 바이너리 포맷(protobuf)으로 저장한 `frozen.pb` 파일을 사용하여 로컬 상에서 추론을 수행합니다. \n",
    "이를 통해 아래의 작업들을 쉽고 빠르게 수행할 수 있습니다.\n",
    "\n",
    "- TFLite 변환 전, 테스트셋 상에서 모델 추론 성능의 빠른 검증\n",
    "- TFLite 변환 전/후 성능 편차 테스트\n",
    "- 검증 데이터 및 테스트 데이터에 대해 추론 결과가 좋지 않은 경우들(예: 오분류, 미검출, 낮은 예측 score 등)에 대해 Amazon Augmented AI(이하 A2I)를 사용하여 모델 성능 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inference Graph 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "model_filepath = './model_result/inference_graph_frozen.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론을 수행하기 위한 그래프를 작성합니다. 물론 추론 컨테이너 환경을 구축하여 SageMaker 엔드포인트 배포하여 추론을 수행할 수도 있지만, \n",
    "실습의 편의성을 위해 별도의 추론 컨테이너 없이 곧바로 네트워크 구조와 모델 파라메터를 로드하여 추론을 수행하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetInference(object):\n",
    "    \n",
    "    def __init__(self, model_filepath, class_map):\n",
    "        self.model_filepath = model_filepath\n",
    "        self.class_map = class_map\n",
    "        self.load_graph(model_filepath = model_filepath)\n",
    "        \n",
    "        \n",
    "    def load_graph(self, model_filepath):\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        # Load the protobuf model file(.pb) and parse it to retrive the graph \n",
    "        with tf.gfile.GFile(model_filepath, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())   \n",
    "        \n",
    "        # Set default graph as graph\n",
    "        with self.graph.as_default():\n",
    "            tf.import_graph_def(graph_def, input_map=None, return_elements=None, name=\"\")   \n",
    "            self.net_input = self.graph.get_tensor_by_name('input:0')\n",
    "            self.net_output = self.graph.get_tensor_by_name('MobilenetV1/Predictions/Reshape_1:0')\n",
    "        \n",
    "        # Avoid to change graph\n",
    "        self.graph.finalize()\n",
    "        \n",
    "        self.sess = tf.Session(graph = self.graph)\n",
    "        self.input_node_info = [n for n in graph_def.node if n.op == 'Placeholder']\n",
    "  \n",
    "\n",
    "    def get_all_tensors(self):    \n",
    "        all_tensors = [tensor for op in self.graph.get_operations() for tensor in op.values()]\n",
    "        return all_tensors\n",
    "    \n",
    "    \n",
    "    def get_input_node_info(self):\n",
    "        return self.input_node_info[0]\n",
    "    \n",
    "    def predict(self, img_filepath, img_size=128, show_image=True):    \n",
    "        # Open image data and resize it\n",
    "        img = Image.open(img_filepath)\n",
    "        img = img.resize((img_size, img_size)) \n",
    "        img_arr = np.asarray(img)\n",
    "        if show_image: \n",
    "            imshow(img_arr)\n",
    "        img_arr = img_arr[np.newaxis, :]\n",
    "\n",
    "        # Get predictions\n",
    "        pred_scores = self.sess.run(self.net_output, feed_dict={self.net_input: img_arr} )\n",
    "        pred_label = np.argmax(pred_scores, axis=1)[0]\n",
    "        pred_label_str = class_map[pred_label]\n",
    "        pred_score = pred_scores[0][pred_label]\n",
    "        \n",
    "        return pred_label, pred_label_str, pred_score   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델은 초기화 시에만 생성하여 메모리에 로드합니다. 매번 입력 데이터에 대해 모델을 재생성하는 것은 많은 지연 시간을 초래합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'background', 1:'dog'}\n",
    "model = MobileNetInference(model_filepath, class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = model.get_all_tensors()\n",
    "print(all_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_input_node_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 샘플 데이터 추론\n",
    "\n",
    "앞에서 정의한 클래스의 predict 메소드를 사용하여 간단하게 이미지 파일에 대한 추론 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dog_img_path = './test_samples/dog'\n",
    "test_dog_img_list = [f for f in listdir(test_dog_img_path) if isfile(join(test_dog_img_path, f))]\n",
    "\n",
    "test_bg_img_path = './test_samples/background'\n",
    "test_bg_img_list = [f for f in listdir(test_bg_img_path) if isfile(join(test_bg_img_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filepath = os.path.join(test_dog_img_path, test_dog_img_list[0])\n",
    "model.predict(img_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filepath = os.path.join(test_dog_img_path, test_dog_img_list[1])\n",
    "model.predict(img_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 배치 데이터 추론\n",
    "여러분의 개인 랩탑/데스크탑이나 온프레미스에서 수행하는 방법과 동일하게 배치 데이터도 쉽게 추론이 가능합니다. 본 예시에서는 테스트 데이터에 대해서\n",
    "간단하게 배치 추론을 수행해 보고, 기본적인 평가 지표들인 Confusion Matrix, AUROC(Area Under a ROC Curve), AUPRC(Area Under a Precision-Recall Curve)를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import collections\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, accuracy_score, roc_curve, average_precision_score,\n",
    "                            precision_recall_curve, precision_score, recall_score, f1_score, matthews_corrcoef, auc)\n",
    "try:\n",
    "    from joblib import dump, load\n",
    "except ImportError:\n",
    "    from sklearn.externals.joblib import dump, load\n",
    "\n",
    "def plot_roc_curve(y_true, y_score, is_single_fig=False):\n",
    "    \"\"\"\n",
    "    Plot ROC Curve and show AUROC score\n",
    "    \"\"\"    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.title('AUROC = {:.4f}'.format(roc_auc))\n",
    "    plt.plot(fpr, tpr, 'b')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([-0.05,1.05])\n",
    "    plt.ylim([-0.05,1.05])\n",
    "    plt.ylabel('TPR(True Positive Rate)')\n",
    "    plt.xlabel('FPR(False Positive Rate)')\n",
    "    if is_single_fig:\n",
    "        plt.show()\n",
    "    \n",
    "def plot_pr_curve(y_true, y_score, is_single_fig=False):\n",
    "    \"\"\"\n",
    "    Plot Precision Recall Curve and show AUPRC score\n",
    "    \"\"\"\n",
    "    prec, rec, thresh = precision_recall_curve(y_true, y_score)\n",
    "    avg_prec = average_precision_score(y_true, y_score)\n",
    "    plt.title('AUPRC = {:.4f}'.format(avg_prec))\n",
    "    plt.step(rec, prec, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(rec, prec, step='post', alpha=0.2, color='b')\n",
    "    plt.plot(rec, prec, 'b')\n",
    "    plt.xlim([-0.05,1.05])\n",
    "    plt.ylim([-0.05,1.05])\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Recall')\n",
    "    if is_single_fig:\n",
    "        plt.show()\n",
    "\n",
    "def plot_conf_mtx(y_true, y_score, thresh=0.5, class_labels=['0','1'], is_single_fig=False):\n",
    "    \"\"\"\n",
    "    Plot Confusion matrix\n",
    "    \"\"\"    \n",
    "    y_pred = np.where(y_score >= thresh, 1, 0)\n",
    "    print(\"confusion matrix (cutoff={})\".format(thresh))\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "    conf_mtx = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(conf_mtx, xticklabels=class_labels, yticklabels=class_labels, annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    if is_single_fig:\n",
    "        plt.show()\n",
    "\n",
    "def prob_barplot(y_score, bins=np.arange(0.0, 1.11, 0.1), right=False, filename=None, figsize=(10,4), is_single_fig=False):\n",
    "    \"\"\"\n",
    "    Plot barplot by binning predicted scores ranging from 0 to 1\n",
    "    \"\"\"    \n",
    "    c = pd.cut(y_score, bins, right=right)\n",
    "    counts = c.value_counts()\n",
    "    percents = 100. * counts / len(c)\n",
    "    percents.plot.bar(rot=0, figsize=figsize)\n",
    "    plt.title('Histogram of score')\n",
    "    print(percents)\n",
    "    if filename is not None:\n",
    "        plt.savefig('{}.png'.format(filename))   \n",
    "    if is_single_fig:\n",
    "        plt.show()\n",
    "    \n",
    "def evaluate_prediction(y_true, y_score, thresh=0.5):\n",
    "    \"\"\"\n",
    "    All-in-one function for evaluation. \n",
    "    \"\"\"    \n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plot_roc_curve(y_true, y_score)\n",
    "    plt.subplot(1,3,2)    \n",
    "    plot_pr_curve(y_true, y_score)\n",
    "    plt.subplot(1,3,3)    \n",
    "    plot_conf_mtx(y_true, y_score, thresh) \n",
    "    plt.show()\n",
    "\n",
    "def get_score_df(y_true, y_score, start_score=0.0, end_score=0.7, cutoff_interval=0.05):\n",
    "    \"\"\"\n",
    "    Get a dataframe contains general metrics\n",
    "    \"\"\"    \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    score = []\n",
    "    \n",
    "    for cutoff in np.arange(start_score, end_score+0.01, cutoff_interval)[1:]:\n",
    "        y_pred = np.where(y_score >= cutoff, 1, 0)\n",
    "        conf_mat = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = conf_mat[0,0], conf_mat[0,1], conf_mat[1,0], conf_mat[1,1]\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        if precision !=0 and recall !=0 :\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "        else:\n",
    "            f1 = 0     \n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        score.append([cutoff, tp, fp, tn, fn, precision, recall, f1, mcc])\n",
    "        \n",
    "    score_df = pd.DataFrame(score, columns = ['Cutoff', 'TP', 'FP', 'TN' ,'FN', 'Precision', 'Recall', 'F1', 'MCC'])\n",
    "    return score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(test_img_list, test_img_path):\n",
    "    num_test = len(test_img_list)\n",
    "    y_score = np.zeros(num_test)\n",
    "\n",
    "    for idx, fname in enumerate(test_img_list):\n",
    "        img_filepath = os.path.join(test_img_path, fname)\n",
    "        pred_cls, pred_cls_str, pred_score = model.predict(img_filepath, show_image=False)\n",
    "        y_score[idx] = pred_score    \n",
    "        \n",
    "    return y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dog_score = get_test_scores(test_dog_img_list, test_dog_img_path)\n",
    "y_dog_true = np.zeros(len(test_dog_img_list)) + 1\n",
    "\n",
    "y_bg_score = get_test_scores(test_bg_img_list, test_bg_img_path)\n",
    "y_bg_true = np.zeros(len(test_bg_img_list)) + 0\n",
    "\n",
    "y_score = np.append(y_dog_score, y_bg_score)\n",
    "y_true = np.append(y_dog_true, y_bg_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_prediction(y_true, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
