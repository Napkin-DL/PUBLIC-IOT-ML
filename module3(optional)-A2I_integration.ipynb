{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3(Optional). Amazon A2I(Augmented AI) integration with Amazon SageMaker Inference\n",
    "\n",
    "***[Note] 본 핸즈온은 필수가 아니며, 앞의 핸즈온들을 수월하게 마치셨을 경우에만 수행하시는 것을 권장드립니다.***\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "이 튜토리얼에서는 검증 데이터 및 테스트 데이터에 대해 추론 결과가 좋지 않은 경우들(예: 오분류, 미검출, 낮은 예측 score 등)에 대해 Amazon Augmented AI(이하 A2I)를 사용하는 법을 수행해 보겠습니다. 이를 통해 추론 결과에 대한 보정이나 점진적 훈련(incremental training)을 통해\n",
    "모델 성능을 개선시킬 수 있습니다.\n",
    "\n",
    "참고로 A2I는 워크샵을 위해 간소화하였기 때문에, 실제 프로덕션 적용 시에는 엣지 디바이스의 추론 결과를 IoT Core를 통해 AWS로 전송하여 A2I 및 점진적 훈련 수행 후 다시 엣지 디바이스로 배포하는 것을 권장드립니다. 아래는 프로덕션 적용 예시입니다.\n",
    "  \n",
    "- 어느 정도 학습이 완료된 모델 아티팩트를 s3에 미리 저장 (핸즈온 시간 단축 및 일관성 있는 성능을 위해)\n",
    "- S3에 저장된 pre-trained 모델을 불러와서 1 epoch만 Incremental training (학습 데이터/검증 데이터 동일)\n",
    "- 검증 데이터셋에서 추론 후, 오검출/미검출되거나 score가 낮은 샘플들 중 2-5장에 대해 A2I 수행(deploy는 로컬 모드에서 수행하거나 `model.tar.gz`를 로컬로 가져와서 직접 수행)\n",
    "- Workteam (private team) 생성\n",
    "- 휴먼 리뷰어의 작업이 완료 후 A2I JSON output 자동 생성\n",
    "- A2I의 JSON output을 Ground Truth의 Augmented manifest 파일로 변환\n",
    "- Augmented manifest 파일을 이용해 Incremental training 수행 (학습 데이터 2~5장만 사용)\n",
    "- Score가 낮은 샘플에 대해 재학습한 모델로 추론 결과 보여주기 (deploy는 로컬 모드에서 수행하거나 model.tar.gz를 로컬로 가져와서 직접 수행)\n",
    "- Edge 배포용 모델로 컴파일 \n",
    "\n",
    "## Amazon A2I란?\n",
    "Amazon A2I를 사용하면 머신 러닝 추론 결과가 잘못되거나 score가 낮은 경우, 사람(휴먼 리뷰어)이 개입하여 추론 결과를 보완하고 선택적으로 보완된 결과를 점진적 훈련(incremental training)을 통해 반영하는 머신 러닝 워크플로를 쉽게 구축할 수 있습니다.\n",
    "\n",
    "Amazon A2I를 휴먼 리뷰 워크플로에 통합하려면 다음 세 가지 리소스들이 필요합니다.\n",
    "\n",
    "* **Worker task template**: 작업자(worker) UI를 만들기 위한 템플릿입니다. Worker UI를 통해 휴먼 리뷰어에게 지시 사항 및 작업을 완료할 수 있는 interactive 도구들을 제공합니다. 자세한 내용은 https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-instructions-overview.html 을 참조하세요.\n",
    "\n",
    "* **Human review workflow**: 흐름 정의(flow definition)라고도 하는 휴먼 리뷰 워크플로우입니다. 이 흐름 정의를 사용하여 인력을 구성하고 인력 검토 작업을 수행하는 방법에 대한 정보를 제공합니다. A2I 콘솔 또는 A2I API를 사용하여 흐름 정의를 생성할 수 있습니다. 자세한 내용은 https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html 을 참조하세요.\n",
    "\n",
    "* **Human loop**: 휴먼 리뷰 워크플로를 시작하는 휴먼 루프입니다. 휴먼 루프가 트리거되면 플로우 정의에 지정된 대로 휴먼 검토 태스크가 휴먼 리뷰어에게(즉, 작업자)에게 전송됩니다.\n",
    "\n",
    "\n",
    "A2I에 대한 자세한 설명은 아래 웹페이지들을 참조해 주세요.\n",
    "- https://aws.amazon.com/augmented-ai/ \n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-getting-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference Graph 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import inference_utils as iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./img_datasets/labels.txt') as f:\n",
    "    l_lines = f.readlines()\n",
    "    labels = [ line.replace('\\n','') for line in l_lines ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델은 초기화 시에만 생성하여 메모리에 로드합니다. 매번 입력 데이터에 대해 모델을 재생성하는 것은 많은 지연 시간을 초래합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath='./model_result/inference_graph_frozen.pb'\n",
    "model = iu.MobileNetInference(model_filepath, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = model.get_all_tensors()\n",
    "print(all_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_input_node_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 샘플 데이터 추론\n",
    "\n",
    "앞에서 정의한 클래스의 predict 메소드를 사용하여 간단하게 이미지 파일에 대한 추론 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = './samples/*/*'\n",
    "test_img_list = glob.glob(test_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀을 여러 번 반복해 보세요 :) `CTRL+Enter` 단축키를 사용하시면 편리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0,len(test_img_list))\n",
    "test_image = test_img_list[idx]\n",
    "print(test_image)\n",
    "model.predict(test_image, img_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = model.get_all_tensors()\n",
    "print(all_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_input_node_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 배치 데이터 추론\n",
    "\n",
    "여러분의 개인 랩탑/데스크탑이나 온프레미스에서 수행하는 방법과 동일하게 배치 데이터도 쉽게 추론이 가능합니다.  \n",
    "본 예시에서는 테스트 데이터에 대해서 간단하게 배치 추론을 수행해 보고, 기본적인 평가 지표들인 ```Confusion Matrix```, ```AUROC(Area Under a ROC Curve)```, ```AUPRC(Area Under a Precision-Recall Curve)```를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnum_to_classname = {}\n",
    "classname_to_classnum = {}\n",
    "for class_name in labels:\n",
    "    cls_split = class_name.split(':')\n",
    "    classnum_to_classname[int(cls_split[0])] = cls_split[1]\n",
    "    classname_to_classnum[cls_split[1]] = int(cls_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = './samples/*/*'\n",
    "test_img_list = glob.glob(test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_str = [img_list.split('/')[2] for img_list in test_img_list]\n",
    "y_true = np.array([classname_to_classnum[s] for s in y_true_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀에서 테스트 데이터셋에 대한 추론을 아래 절차로 수행합니다. \n",
    "\n",
    "- 정답값에 대한 One-hot encoding 변환 수행\n",
    "- 배치 추론을 수행 후, 예측 score 및 결과(class) 리턴\n",
    "- 예측 결과에 대한 One-hot encoding 변환 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categories='auto', sparse=False)\n",
    "num_classes = len(labels)\n",
    "\n",
    "y_true_ohe = enc.fit_transform(y_true.reshape(-1, 1))\n",
    "y_score, y_pred = iu.get_test_scores(model, test_img_list, '', num_classes)\n",
    "y_pred_ohe = enc.transform(y_pred.reshape(-1,1))\n",
    "\n",
    "y_pred_str = [classnum_to_classname[int(score)] for score in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋에서 몇 개의 샘플 데이터만 가져옵니다. 참고로, 본 핸즈온에서는 20개의 샘플 데이터를 가져옵니다. 이 샘플 데이터로 A2I를 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_SAMPLES = 20\n",
    "y_pred[:NUM_TEST_SAMPLES], y_pred_str[:NUM_TEST_SAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Human review Workteam or Workforce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인력(workforce)은 데이터셋에 레이블을 지정하기 위해 선택한 작업자 그룹입니다. 벤더가 관리하는 인력인 Amazon Mechanical Turk 인력을 선택하거나, private 인력을 생성할 수 있습니다.\n",
    "\n",
    "본 섹션에서는 AWS 콘솔로 private 인력을 생성하겠습니다. 아래 순서를 따라 priavte 팀을 생성 후 한 명의 리뷰어를 추가해 봅시다.\n",
    "역할(role)에 필요한 권한을 추가하려면 https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-permissions-security.html 을 참조해 주세요.\n",
    "\n",
    "1. AWS Console > Amazon SageMaker > **`Labeling workforces(레이블링 인력)`** 으로 이동 후, 상단의 **`Private(프라이빗)`** 탭을 클릭합니다.\n",
    "2. 상단의 **`Private`** 탭을 클릭 후, **`Create private team(프라이빗 팀 만들기)`** 버튼을 클릭합니다.\n",
    "3. Team name 이름에 임의의 이름을 입력하고 **`Create a new Amazon Cognito user group(Amazon Cognito 사용자 그룹 새로 만들기)`** 을 선택한 다음, 하단의 **`Create private team(프라이빗 팀 만들기)`** 버튼을 클릭합니다.\n",
    "![Fig01](./imgs/fig01.png)\n",
    "<br>\n",
    "4. Amazon SageMaker > Labeling workforces 화면 맨 아래의 **`Workers(작업자)`** 탭에셔, 우측 하단의 **`Invite new workers(새 작업자 초대)`** 버튼을 클릭합니다.\n",
    "![Fig02](./imgs/fig02.png)\n",
    "<br>\n",
    "5. 이메일 주소 항목에 여러분의 이메일 주소를 입력하고 **`Invite new workers(새 작업자 초대)`** 버튼을 클릭합니다.\n",
    "![Fig03](./imgs/fig03.png)\n",
    "<br>\n",
    "6. Amazon SageMaker > Labeling workforces 화면으 **`Private teams`** 탭에서 여러분이 아까 생성한 private team 이름의 링크를 클릭합니다.\n",
    "![Fig04](./imgs/fig04.png)\n",
    "<br>\n",
    "7. Workers 탭을 클릭 후, **`Add workers to team(팀에 작업자 추가)`** 버튼을 클릭합니다.\n",
    "![Fig05](./imgs/fig05.png)\n",
    "<br>\n",
    "8. 이메일 주소를 선택 후, **`Add workers to team(팀에 작업자 추가)`** 버튼을 클릭합니다.\n",
    "![Fig06](./imgs/fig06.png)\n",
    "<br>\n",
    "9. Private team 항목에서 private team 이름의 링크를 클릭하면, ARN을 아래 화면과 같이 확인할 수 있습니다. 이 arn을 아래 코드 셀에 붙여 넣으시면 됩니다.\n",
    "    - `arn:aws:sagemaker:[YOUR REGION]:[YOUR ACCOUNT ID]:workteam/private-crowd/[YOUR PRIVATE TEAM NAME]`\n",
    "![Fig07](./imgs/fig07.png)   \n",
    "<br>\n",
    "10. 참고로, 라벨링 작업이 이루어지는 포털 로그인 URL은 **`Private workforce summary(프라이빗 작업 인력 요약)`** 항목의 **`Labeling portal sign-in URL(레이블 지정 포털 로그인 URL)`** 입니다. 먼저, 여러분이 입력한 이메일을 확인하면 아래 그림과 같은 메일을 받을 수 있고, 이에 따라 포털로 로그인하시면 라벨링 작업을 수행하는 페이지로 접속할 수 있습니다. Human Loop가 활성화되면 여기에 신규 워크로드가 생성됩니다. \n",
    "![Fig08](./imgs/fig08.png)   \n",
    "![Fig09](./imgs/fig09.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상기 과정에서 복사한 `arn:aws:sagemaker:[YOUR REGION]:[YOUR ACCOUNT ID]:workteam/private-crowd/[YOUR PRIVATE TEAM NAME]` 을 아래의 코드 셀에 붙여 넣어 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN = \"arn:aws:sagemaker:[YOUR REGION]:[YOUR ACCOUNT ID]:workteam/private-crowd/[YOUR PRIVATE TEAM NAME]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A2I Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import uuid\n",
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import time\n",
    "import json\n",
    "\n",
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker', region)\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# Amazon S3 client \n",
    "s3 = boto3.client('s3', region)\n",
    "\n",
    "# Flow definition name - 이 값은 계정 및 지역마다 고유합니다. 여기에서 여러분의 고유 값을 제공할 수도 있습니다.\n",
    "flowDefinitionName = 'fd-sagemaker-iot-public-workshop-demo-' + timestamp\n",
    "\n",
    "# Task UI name - 이 값은 계정 및 지역마다 고유합니다. 여기에서 여러분의 고유 값을 제공할 수도 있습니다.\n",
    "taskUIName = 'ui-sagemaker-iot-public-workshop-demo-' + timestamp\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "BUCKET = sess.default_bucket()\n",
    "OUTPUT_PATH = 's3://{}/a2i-results'.format(BUCKET)\n",
    "MODEL_PATH = 's3://{}/model'.format(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.  Human Task UI 생성\n",
    "\n",
    "HTML로 구성된 UI 템플릿으로 휴먼 작업 UI 리소스를 생성할 수 있으며, 이 템플릿은 휴먼 루프가 필요할 때마다 휴먼 워커에게 렌더링됩니다.\n",
    "참고로, 사전에 구축된 70여 가지의 UI를 https://github.com/aws-samples/amazon-a2i-sample-task-uis 에서 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "  <crowd-image-classifier\n",
    "    name=\"annotatedResult\"\n",
    "    src=\"{{ task.input.taskObject | grant_read_access }}\"\n",
    "    header=\"Please identify the class in this image\"  \n",
    "    categories=\"['4:British_Shorthair', '6:english_cocker_spaniel', \n",
    "    '9:Sphynx', '11:staffordshire_bull_terrier', '17:havanese',\n",
    "    '28:scottish_terrier', '32:Russian_Blue']\"\n",
    "  >\n",
    "    <full-instructions header=\"Classification Instructions\">\n",
    "      <p>Read the task carefully and inspect the image.</p>\n",
    "      <p>Choose the appropriate label(s) that best suits the image.</p>\n",
    "    </full-instructions>\n",
    "\n",
    "    <short-instructions>\n",
    "      <p>Read the task carefully and inspect the image.</p>\n",
    "      <p>Choose the appropriate label that best suits the image.</p>\n",
    "    </short-instructions>\n",
    "  </crowd-image-classifier>\n",
    "</crowd-form>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker_client.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Human Review Workflow 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 섹션에서는 플로우 정의를 작성합니다. 플로우 정의를 통해 다음을 지정할 수 있습니다.\n",
    "\n",
    "- 작업을 수행할 인력\n",
    "- Worker task template; 인력이 받을 지침\n",
    "- 작업을 받는 작업자 수 및 작업을 완료하기 위한 시간 제한을 포함한 worker task 구성\n",
    "- 출력 데이터가 저장될 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "create_workflow_definition_response = sagemaker_client.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn= role,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Identifythe class in an image.\",\n",
    "            \"TaskTitle\": \"Image Classification a2i demo-hol\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flow Definition 생성 결과를 아래 코드 셀을 통해 확인합니다. Status는 `Active`가 되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker_client.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Human Loop 시작\n",
    "\n",
    "휴먼 리뷰 워크플로를 설정했으므로 휴먼 루프를 시작할 준비가 되었습니다. 여기에서 예측 결과가 좋지 않는 경우에만 Human Loop를 시작합니다.\n",
    "\n",
    "먼저, A2I UI가 표시할 샘플 이미지를 s3 버킷에 복사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync ./samples s3://{BUCKET}/a2i-results/sample-a2i-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_loops_started = []\n",
    "\n",
    "for fname, true_cls in (zip(test_img_list[:NUM_TEST_SAMPLES], y_true[:NUM_TEST_SAMPLES])):\n",
    "    \n",
    "    pred_cls, pred_cls_str, pred_score, pred_scores = model.predict(fname, show_image=False)  \n",
    "    true_cls_str = '{}:{}'.format(true_cls, classnum_to_classname[true_cls])\n",
    "    \n",
    "    if pred_cls != true_cls:\n",
    "        split = fname.split('/')\n",
    "        s3_fname = 's3://%s/a2i-results/sample-a2i-images/%s/%s' % (BUCKET, split[2], split[3])\n",
    "        humanLoopName = str(uuid.uuid4())        \n",
    "        inputContent = {\n",
    "            \"initialValue\": pred_cls_str,\n",
    "            \"taskObject\": s3_fname # the s3 object will be passed to the worker task UI to render\n",
    "        }\n",
    "        # start an a2i human review loop with an input\n",
    "        start_loop_response = a2i.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(inputContent)\n",
    "            }\n",
    "        )\n",
    "        human_loops_started.append(humanLoopName)\n",
    "        msg = \"The model had to predict '{}', but incorrectly predicted '{}'.\".format(true_cls_str, pred_cls_str)\n",
    "\n",
    "        print(s3_fname)\n",
    "        print(msg)\n",
    "        print('Starting human loop with name: {} \\n'.format(humanLoopName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Human Loop Status 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print('HumanLoop Name: {}'.format(human_loop_name))\n",
    "    print('HumanLoop Status: {}'.format(resp[\"HumanLoopStatus\"]))\n",
    "    print('HumanLoop Output Destination: {}'.format(resp[\"HumanLoopOutput\"]))\n",
    "    print('\\n')\n",
    "    \n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 코드셀 수행 후, A2I를 작업할 수 있는 전용 URL이 출력됩니다. 이 URL로 접속 후에 SSO(Single Sign On)으로 로그인하면 아래 figure와 같은 화면이 출력됩니다. Start working 버튼을 클릭하여 레이블링 작업을 시작합니다.<br>\n",
    "\n",
    "![Fig10](./imgs/fig10.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker_client.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀은 바로 2번째 위의 코드 셀과 동일합니다. 이 코드 셀을 실행하여 **HumanLoop Status**를 확인합니다.\n",
    "모든 HumanLoop의 Status가 `Completed` 가 되어야 합니다. 참고로, A2I 전용 URL에서 레이블링 작업이 완료되면 아래 figure와 같은 화면이 출력됩니다.\n",
    "\n",
    "![Fig11](./imgs/fig11.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print('HumanLoop Name: {}'.format(human_loop_name))\n",
    "    print('HumanLoop Status: {}'.format(resp[\"HumanLoopStatus\"]))\n",
    "    print('HumanLoop Output Destination: {}'.format(resp[\"HumanLoopOutput\"]))\n",
    "    print('\\n')\n",
    "    \n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. View Task Results  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블링 결과를 아래 코드셀을 통해 쉽게 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' +  BUCKET + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    # load json\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Incremental Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과를 JSON 형태의 augmented Manifest 파일로 변경하거나 S3에 저장된 메타데이터 정보를 파싱 후 feature set(예: JPEG, TFRecord, RecordIO 등)으로 변환하여 점진적 훈련을 수행할 수 있습니다. 점진적 훈련은 모든 데이터를 다시 재훈련할 필요 없이\n",
    "사전 훈련된 모델을 가져온 다음, 휴먼 리뷰어가 수정한 레이블링 결과만 입력 데이터로 사용하기에 훈련 시간이 오래 걸리지 않습니다.\n",
    "\n",
    "본 핸즈온은 점진적 훈련까지 수행하지 않습니다. 만약 점진적 훈련에 대한 상세한 내용이나 예제 코드가 필요하면 아래 AWS 블로그를 참조해 주세요.\n",
    "\n",
    "https://aws.amazon.com/ko/blogs/machine-learning/object-detection-and-model-retraining-with-amazon-sagemaker-and-amazon-augmented-ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
