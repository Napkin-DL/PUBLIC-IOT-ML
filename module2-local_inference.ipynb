{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2. Local Inference\n",
    "\n",
    "***[주의] 본 노트북은 Python 2가 아닌 Python 3에서 실행하셔야 합니다. 배치 데이터 추론 결과에 대한 다중 클래스 분류(multi-class classification) 지표(metric) 계산 시 scikit-learn 0.23.1 버전 기준의 빌트인 함수를 사용하는데, scikit-learn이 0.20 버전 이후로는 Python 2를 지원하지 않기 때문입니다.***\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "이 튜토리얼에서는 이전 노트북에서 Amazon SageMaker의 Tensorflow 1.x 사용자 스크립트로 학습한 MobileNet 모델 아티팩트 중 네트워크 구조와 가중치를 바이너리 포맷(protobuf)으로 저장한 `frozen.pb` 파일을 사용하여 로컬 상에서 추론을 수행합니다. \n",
    "이를 통해 아래의 작업들을 쉽고 빠르게 수행할 수 있습니다.\n",
    "\n",
    "- TFLite 변환 전, 테스트셋 상에서 모델 추론 성능의 빠른 검증\n",
    "- TFLite 변환 전/후 성능 편차 테스트\n",
    "- 검증 데이터 및 테스트 데이터에 대해 추론 결과가 좋지 않은 경우들(예: 오분류, 미검출, 낮은 예측 score 등)에 대해 Amazon Augmented AI(이하 A2I)를 사용하여 모델 성능 개선\n",
    "\n",
    "물론 추론 컨테이너 환경을 구축하여 SageMaker 엔드포인트 배포하여 추론을 수행할 수도 있지만, 실습의 편의성을 위해 별도의 추론 컨테이너 없이 곧바로 네트워크 구조와 모델 파라메터를 로드하여 추론을 수행하겠습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference Graph 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from utils import inference_utils as iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./img_datasets/labels.txt') as f:\n",
    "    l_lines = f.readlines()\n",
    "    labels = [ line.replace('\\n','') for line in l_lines ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델은 초기화 시에만 생성하여 메모리에 로드합니다. 매번 입력 데이터에 대해 모델을 재생성하는 것은 많은 지연 시간을 초래합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_filepath='./model_result/inference_graph_frozen.pb'\n",
    "model = iu.MobileNetInference(model_filepath, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = model.get_all_tensors()\n",
    "print(all_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_input_node_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 샘플 데이터 추론\n",
    "\n",
    "앞에서 정의한 클래스의 predict 메소드를 사용하여 간단하게 이미지 파일에 대한 추론 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = './samples/*/*'\n",
    "test_img_list = glob.glob(test_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀을 여러 번 반복해 보세요 :) `CTRL+Enter` 단축키를 사용하시면 편리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0,len(test_img_list))\n",
    "test_image = test_img_list[idx]\n",
    "print(test_image)\n",
    "model.predict(test_image, img_size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 배치 데이터 추론\n",
    "\n",
    "여러분의 개인 랩탑/데스크탑이나 온프레미스에서 수행하는 방법과 동일하게 배치 데이터도 쉽게 추론이 가능합니다.  \n",
    "본 예시에서는 테스트 데이터에 대해서 간단하게 배치 추론을 수행해 보고, 기본적인 평가 지표들인 ```Confusion Matrix```, ```AUROC(Area Under a ROC Curve)```, ```AUPRC(Area Under a Precision-Recall Curve)```를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnum_to_classname = {}\n",
    "classname_to_classnum = {}\n",
    "for class_name in labels:\n",
    "    cls_split = class_name.split(':')\n",
    "    classnum_to_classname[int(cls_split[0])] = cls_split[1]\n",
    "    classname_to_classnum[cls_split[1]] = int(cls_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = './samples/*/*'\n",
    "test_img_list = glob.glob(test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_str = [img_list.split('/')[2] for img_list in test_img_list]\n",
    "y_true = np.array([classname_to_classnum[s] for s in y_true_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀에서 테스트 데이터셋에 대한 추론을 아래 절차로 수행합니다. \n",
    "\n",
    "- 정답값에 대한 One-hot encoding 변환 수행\n",
    "- 배치 추론을 수행 후, 예측 score 및 결과(class) 리턴\n",
    "- 예측 결과에 대한 One-hot encoding 변환 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categories='auto', sparse=False)\n",
    "num_classes = len(labels)\n",
    "\n",
    "y_true_ohe = enc.fit_transform(y_true.reshape(-1, 1))\n",
    "y_score, y_pred = iu.get_test_scores(model, test_img_list, '', num_classes)\n",
    "y_pred_ohe = enc.transform(y_pred.reshape(-1,1))\n",
    "\n",
    "y_pred_str = [classnum_to_classname[int(score)] for score in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10], y_pred_str[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 클래스의 plotting에 필요한 컬러 테이블을 랜덤하게 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "color_table = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu.plot_conf_mtx_multiclass(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu.plot_roc_curve_multiclass(y_true_ohe, y_score, num_classes, color_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu.plot_pr_curve_multiclass(y_true_ohe, y_score, num_classes, color_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
